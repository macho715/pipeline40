제안 아키텍처 (독립 모듈화)

새 패키지 headers/를 파이프라인에 추가합니다. 각 스테이지는 더 이상 실제 엑셀 헤더 문자열에 의존하지 않고 표준 의미 키만 사용합니다.

headers/
  ├─ normalizer.py      # 전각→반각(NFKC), 공백/기호 통합, 토큰화/키 정규화
  ├─ aliases.py         # 의미별 동의어 사전(프로젝트 컬럼 정의에서 자동 생성 + 수동 추가)
  ├─ detector.py        # 헤더 행/시작 열 자동 탐지 (pandas/openpyxl 모두 지원)
  └─ resolver.py        # 스테이지별 요구 헤더 의미→실제 컬럼 매핑(퍼지 매칭 포함)


헤더 행/시작 열 자동 탐지: 시트 상단 N개 행을 스캔해 “동의어 매칭 점수”가 가장 높은 행을 헤더 행으로 결정하고, 그 행의 시작 열도 함께 추정합니다.

하드코딩 금지: 스테이지는 resolver.resolve(...)로 “의미 키”만 넘깁니다. 실제 파일에선 무엇이라 적혀 있어도 문제 없음.

퍼지 매칭(옵션): 정확 일치가 없으면 RapidFuzz로 의미-헤더 유사도를 계산해 임계치 이상만 허용(없으면 안전하게 실패). pyjanitor의 clean_names류 정규화 아이디어와 궁합이 좋아요. 
rapidfuzz.github.io
+3
GitHub
+3
KDnuggets
+3

엑셀 헤더 위치 변동 대응: pandas.read_excel(..., header=None)로 원시 행렬을 읽고, 휴리스틱으로 헤더 행을 잡은 후 그 행을 헤더로 재지정합니다. (pandas 문서 및 커뮤니티 관행 참고) 
Data Science Stack Exchange
+3
Pandas
+3
Pandas
+3

코드 (드롭인 모듈)

아래 코드는 외부 의존성 없이 동작합니다. rapidfuzz가 설치되어 있으면 자동으로 퍼지 매칭을 사용합니다(선택).

headers/normalizer.py
# -*- coding: utf-8 -*-
from __future__ import annotations
import re
import unicodedata
from typing import Iterable

_WORD_RE = re.compile(r"\w+", flags=re.UNICODE)

def to_nfkc(s: str) -> str:
    # 전각/호환 문자 → 반각 정규화
    return unicodedata.normalize("NFKC", s)

def normalize_key(text: object) -> str:
    """
    헤더 비교용 키 생성:
    - 전각→반각(NFKC)
    - 소문자화
    - 영숫자/언더스코어 외 제거
    - 공백/구분기호 제거(키는 붙여서 비교)
    예: "Ｃａse　No." / "Case No." / "case-no" → "caseno"
    """
    if text is None:
        return ""
    s = to_nfkc(str(text)).strip().lower()
    s = re.sub(r"[^\w]+", " ", s)         # 기호→공백
    s = re.sub(r"\s+", " ", s).strip()    # 공백 정리
    key = re.sub(r"[\W_]+", "", s)        # 공백/기호 제거
    return key

def tokenize(text: object) -> list[str]:
    """검색/퍼지 점수에 쓸 토큰 리스트 (정규화 + 단어 단위)."""
    if text is None:
        return []
    s = to_nfkc(str(text)).lower()
    return _WORD_RE.findall(s)

headers/aliases.py
# -*- coding: utf-8 -*-
from __future__ import annotations
from typing import Dict, Iterable, Set
from .normalizer import normalize_key
# 프로젝트 컬럼 정의에서 창고/현장 컬럼을 불러와 동의어 자동 생성
from ..column_definitions import WAREHOUSE_COLUMNS, SITE_COLUMNS  # 프로젝트 내 경로에 맞게

# 1) 공통 키 의미(케이스 번호/날짜류 등)
BASE_ALIASES: Dict[str, Iterable[str]] = {
    "no": ["no", "num", "number", "index", "id"],
    "caseno": ["case no", "case_no", "case-no", "case number", "caseno", "case"],
    "eta": ["eta", "estimated arrival", "expected arrival", "eta/ata"],
    "etd": ["etd", "estimated departure", "expected departure", "etd/atd"],
    "date": ["date", "datetime", "time", "날짜", "일시"],
    "qty": ["qty", "quantity", "amount", "count", "수량"],
    "description": ["description", "desc", "detail", "name", "품목", "내역"],
}

def _norm_set(words: Iterable[str]) -> Set[str]:
    return {normalize_key(w) for w in words}

def build_alias_index(extra: Dict[str, Iterable[str]] | None = None) -> Dict[str, Set[str]]:
    """
    의미키 → {정규화 동의어 키들}
    - WAREHOUSE/SITE 컬럼명도 의미키로 취급하여 자동 포함
    """
    idx: Dict[str, Set[str]] = {k: _norm_set(v) for k, v in BASE_ALIASES.items()}

    # 2) 위치 컬럼(의미 = 실제 표준 컬럼명)
    for label in list(WAREHOUSE_COLUMNS) + list(SITE_COLUMNS):
        k = normalize_key(label)  # 예: "DSV Al Markaz" → "dsvalmarkaz"
        idx.setdefault(k, set()).update({k, normalize_key(label), normalize_key(label.replace("_", " "))})

    # 3) 추가 사용자 동의어 주입
    if extra:
        for k, vals in extra.items():
            nk = normalize_key(k)
            idx.setdefault(nk, set()).update(_norm_set(vals))
    return idx

DEFAULT_ALIAS_INDEX = build_alias_index()

headers/detector.py
# -*- coding: utf-8 -*-
from __future__ import annotations
from dataclasses import dataclass
from typing import Any, Dict, List, Optional, Sequence, Tuple
import pandas as pd
from .normalizer import normalize_key
from .aliases import DEFAULT_ALIAS_INDEX

try:  # 선택 의존성
    from rapidfuzz import fuzz  # type: ignore
    _HAS_RF = True
except Exception:
    _HAS_RF = False

@dataclass(frozen=True)
class HeaderDetection:
    header_row: int              # 0-based
    start_col: int               # 0-based (최좌측 매칭 열)
    names: List[Any]             # 실제 헤더 셀 값(원본)
    pos_by_meaning: Dict[str, int]   # 의미키(정규화) → 열 인덱스

def _row_score(cells: Sequence[Any], alias_index: Dict[str, set], *, use_fuzzy: bool, cutoff: int) -> Tuple[int, int, Dict[str,int]]:
    """
    반환: (매칭개수, 최초매칭열, 의미→열 인덱스)
    """
    pos_by_meaning: Dict[str, int] = {}
    first_pos = 10**9
    matches = 0

    for j, val in enumerate(cells):
        key = normalize_key(val)
        if not key:
            continue

        # 정확 일치
        for meaning, synonyms in alias_index.items():
            if key in synonyms:
                pos_by_meaning.setdefault(meaning, j)
                matches += 1
                first_pos = min(first_pos, j)
                break
        else:
            # 퍼지(옵션)
            if _HAS_RF and use_fuzzy:
                best_meaning = None
                best_score = 0
                for meaning, synonyms in alias_index.items():
                    for syn in synonyms:
                        score = fuzz.QRatio(key, syn)  # 0~100
                        if score > best_score:
                            best_score, best_meaning = score, meaning
                            if best_score == 100:
                                break
                    if best_score == 100:
                        break
                if best_score >= cutoff and best_meaning is not None:
                    pos_by_meaning.setdefault(best_meaning, j)
                    matches += 1
                    first_pos = min(first_pos, j)

    if first_pos == 10**9:
        first_pos = len(cells)  # 매칭 없음
    return matches, first_pos, pos_by_meaning

def detect_header_row_df(raw: pd.DataFrame, *, scan_rows: int = 20, alias_index: Dict[str, set] = DEFAULT_ALIAS_INDEX,
                         use_fuzzy: bool = True, cutoff: int = 92) -> Optional[HeaderDetection]:
    """
    header=None로 읽은 DF에서 헤더 행/시작열 자동 탐지.
    """
    best = (-1, 10**9, -1, {})  # (매칭개수, 최초열, row_idx, pos_by_meaning)
    scan = min(scan_rows, len(raw))
    for i in range(scan):
        row_vals = [raw.iat[i, j] for j in range(raw.shape[1])]
        m, first_col, pos_map = _row_score(row_vals, alias_index, use_fuzzy=use_fuzzy, cutoff=cutoff)
        if (m, -first_col) > (best[0], -best[1]):  # 매칭 우선, 그다음 좌측정렬 우선
            best = (m, first_col, i, pos_map)

    if best[0] <= 0:
        return None

    header_row = best[2]
    names = [raw.iat[header_row, j] for j in range(raw.shape[1])]
    return HeaderDetection(header_row=header_row, start_col=best[1], names=names, pos_by_meaning=best[3])

# openpyxl 워크시트 지원(색칠 로직과 궁합)
def detect_header_row_openpyxl(ws, *, scan_rows: int = 20, alias_index: Dict[str, set] = DEFAULT_ALIAS_INDEX,
                               use_fuzzy: bool = True, cutoff: int = 92) -> Optional[HeaderDetection]:
    rows = list(ws.iter_rows(min_row=1, max_row=scan_rows, values_only=True))
    if not rows:
        return None

    import pandas as pd
    raw = pd.DataFrame(rows)
    return detect_header_row_df(raw, scan_rows=scan_rows, alias_index=alias_index, use_fuzzy=use_fuzzy, cutoff=cutoff)

headers/resolver.py
# -*- coding: utf-8 -*-
from __future__ import annotations
from typing import Dict, Iterable, List, Optional
import pandas as pd
from .normalizer import normalize_key
from .aliases import DEFAULT_ALIAS_INDEX, build_alias_index
from .detector import detect_header_row_df, HeaderDetection

class HeaderResolver:
    def __init__(self, *, alias_index: Optional[Dict[str, set]] = None, use_fuzzy: bool = True, cutoff: int = 92):
        self.alias_index = alias_index or DEFAULT_ALIAS_INDEX
        self.use_fuzzy = use_fuzzy
        self.cutoff = cutoff

    def detect_and_set_header(self, df_raw: pd.DataFrame) -> tuple[pd.DataFrame, HeaderDetection]:
        """header=None로 읽은 DF → 헤더 자동 감지 후 컬럼명 지정."""
        det = detect_header_row_df(df_raw, alias_index=self.alias_index, use_fuzzy=self.use_fuzzy, cutoff=self.cutoff)
        if det is None:
            raise ValueError("헤더 행을 찾지 못했습니다.")
        renamed = df_raw.iloc[det.header_row + 1:].copy()
        renamed.columns = det.names
        renamed.reset_index(drop=True, inplace=True)
        return renamed, det

    def resolve(self, df_with_header: pd.DataFrame, required_meanings: Iterable[str], optional_meanings: Iterable[str] = ()):
        """
        의미 키 목록을 받아 실제 컬럼명을 매핑.
        반환: {의미키(정규화): 실제컬럼명}
        """
        col_map = {normalize_key(c): str(c) for c in df_with_header.columns}
        result: Dict[str, str] = {}

        # 1) 정확 매칭
        for meaning in required_meanings:
            mk = normalize_key(meaning)
            synonyms = self.alias_index.get(mk, set()) | {mk}
            hit = next((col for key, col in col_map.items() if key in synonyms), None)
            if hit is not None:
                result[mk] = hit
            else:
                # 2) 퍼지(옵션)
                if self.use_fuzzy:
                    try:
                        from rapidfuzz import fuzz  # type: ignore
                        best, best_col = 0, None
                        for key, col in col_map.items():
                            for syn in synonyms:
                                score = fuzz.QRatio(key, syn)
                                if score > best:
                                    best, best_col = score, col
                                    if best == 100:
                                        break
                            if best == 100:
                                break
                        if best_col and best >= self.cutoff:
                            result[mk] = best_col
                    except Exception:
                        pass

        missing = [m for m in map(normalize_key, required_meanings) if m not in result]
        if missing:
            raise KeyError(f"요구 헤더를 찾지 못했습니다: {missing}")
        # optional은 실패해도 예외 X
        for meaning in optional_meanings:
            mk = normalize_key(meaning)
            synonyms = self.alias_index.get(mk, set()) | {mk}
            hit = next((col for key, col in col_map.items() if key in synonyms), None)
            if hit:
                result[mk] = hit
        return result

기존 파이프라인 적용 (핵심 부분만 패치)
1) data_synchronizer_v29.py (이미 유연 매칭 일부 도입되어 있음)

현재도 column_matcher를 불러서 유연 매칭을 사용하고 있어요. 이걸 headers.resolver로 치환하면 헤더 행 탐지/의미 매핑까지 한 번에 처리됩니다.

- from .column_matcher import find_column_flexible, find_column_by_meaning
+ from .headers.resolver import HeaderResolver
+ resolver = HeaderResolver()

# ... 엑셀 읽기 부분 예시 (원시 읽기 후 자동 헤더 지정)
- df = pd.read_excel(path)
+ df_raw = pd.read_excel(path, header=None, dtype=str)  # 헤더 없는 상태로
+ df, _det = resolver.detect_and_set_header(df_raw)

# 필드 매핑(예: Case No, ETA 등)
- case_col = find_column_by_meaning(df, "caseno")
+ cols = resolver.resolve(df, required_meanings=["caseno"], optional_meanings=["eta","etd"])
+ case_col = cols["caseno"]


참고: 기존의 날짜 컬럼 판별 _is_date_col은 의미 키 기반으로 대체 가능(예: "etd/atd", "eta/ata" 등 별칭을 모두 alias에 포함).

2) create_final_colored_report.py의 “Case NO 컬럼 찾기” 교체

현재는 1행에서만 "Case No."/"CASE_NO"를 찾고 실패 시 종료합니다. 자동 헤더 탐지+의미 매핑으로 바꾸면 어떤 행/표기라도 대응합니다.

- # 7. Case NO 컬럼 찾기 (row=1 가정)
- case_col = None
- for col in range(1, ws.max_column + 1):
-     header_value = ws.cell(row=1, column=col).value
-     if header_value and (str(header_value) == "Case No." or "CASE_NO" in str(header_value).upper()):
-         case_col = col
-         ...
- if not case_col:
-     print("ERROR: Case NO 컬럼을 찾을 수 없습니다.")
-     return False
+ # 7. Case NO 컬럼 찾기 (행·열 자동)
+ from .headers.detector import detect_header_row_openpyxl
+ from .headers.normalizer import normalize_key
+ det = detect_header_row_openpyxl(ws, scan_rows=20)
+ if not det:
+     print("ERROR: 헤더 행을 찾을 수 없습니다.")
+     return False
+ # 의미 매핑: 'caseno'
+ mk = normalize_key("caseno")
+ if mk not in det.pos_by_meaning:
+     print("ERROR: Case No 의미를 가진 헤더를 찾을 수 없습니다.")
+     return False
+ header_row_1based = det.header_row + 1
+ case_col = det.pos_by_meaning[mk] + 1  # openpyxl는 1-based
+ print(f"   Case NO 컬럼 탐지: row={header_row_1based}, col={case_col}")

3) derived_columns_processor.py & column_definitions.py

현 구조는 WAREHOUSE_COLUMNS, SITE_COLUMNS 상수를 기준으로 파생 컬럼을 계산합니다(존재하는 컬럼만 사용). 이 상수들은 표준 의미로 보고, 파일 내 실제 헤더와의 매칭은 resolver에서 처리하면 됩니다. 현재 코드도 존재 컬럼만 집계하여 비교적 안전합니다.

사용 예 (엔드투엔드)
from headers.resolver import HeaderResolver
import pandas as pd

resolver = HeaderResolver()  # rapidfuzz 설치 시 퍼지 매칭 자동 사용

# 1) 엑셀을 헤더 없이 읽음
raw = pd.read_excel("input.xlsx", sheet_name=0, header=None, dtype=str)

# 2) 헤더 행/시작열 자동 탐지 → 헤더 지정
df, det = resolver.detect_and_set_header(raw)
print("헤더 행:", det.header_row, "시작 열:", det.start_col)

# 3) 스테이지 요구 헤더 의미 매핑
need = ["caseno", "eta", "dsv al markaz", "aaa  storage"]  # 무엇이든 의미만
cols = resolver.resolve(df, required_meanings=need)
print(cols)  # {"caseno": "Case No.", "eta": "ETA/ATA", "dsvalmarkaz": "DSV Al Markaz", ...}

# 4) 파이프라인 각 단계에서 cols[...]로 안전 참조
case_series = df[cols["caseno"]]

테스트 (pytest)
# tests/test_headers.py
import pandas as pd
from headers.normalizer import normalize_key
from headers.detector import detect_header_row_df
from headers.resolver import HeaderResolver

def test_normalize_fullwidth_kana_space():
    assert normalize_key("Ｃａｓｅ　Ｎｏ．") == "caseno"

def test_detect_header_row_with_offset():
    raw = pd.DataFrame([
        ["", "", "", ""],                    # garbage
        ["Some", "random", "text", ""],      # garbage
        ["Case No.", "ETA/ATA", "DSV Al Markaz", "Qty"],  # <- header
        ["A001", "2024-01-01", "2024-01-03", "10"],
    ])
    det = detect_header_row_df(raw, scan_rows=5)
    assert det and det.header_row == 2
    assert det.pos_by_meaning  # at least one mapping

def test_resolve_required_meanings():
    df = pd.DataFrame(
        [["A001","2024-01-01","5"]],
        columns=["Case Number", "ＥＴＡ", "Quantity"]  # 전각+별칭 혼용
    )
    r = HeaderResolver()
    cols = r.resolve(df, required_meanings=["caseno","eta","qty"])
    assert set(cols.keys()) == {"caseno","eta","qty"}


팀 규약에 맞춰 ruff --fix + black + pytest -q 게이트 통과 기준으로 합류하세요. (v3.8 가이드—Python First)

Tidy First & 커밋 계획

structural(headers): headers/ 패키지 추가, 기존 파일 import 경로만 수정 (행위 불변)

behavioral(sync, report): 헤더 자동 탐지/의미 매핑 활성화, 케이스넘버 탐지 로직 교체

예시 메시지

structural(headers): add header normalizer/detector/resolver modules

behavioral(sync): feat: auto-detect header row & map meanings across stages
behavioral(report): fix: robust Case No detection via header resolver (any row/any form)


머지 전 게이트: 모든 테스트 통과, ruff 0, black OK, (선택) 타입체커, 커버리지 ≥85%.

2× GitHub 교차검증 (요구사항 반영)
레포	우리가 참조한 포인트	차이/채택
pyjanitor (clean_names)	컬럼 정규화의 표준화 컨벤션(소문자/공백·기호 정리, 멀티인덱스 대응)	아이디어 채택. 우리는 전각(NFKC) 추가, 의미 키 중심으로 확장. 
GitHub
+2
pyjanitor-devs.github.io
+2

RapidFuzz	고성능 문자열 유사도(Levenshtein; QRatio)로 퍼지 동의어 매칭 임계치 적용	“정확 일치→퍼지” 2단계 전략 채택. 미설치 환경에선 자동 폴백. 
GitHub
+1

반영/보류

정규화: pyjanitor 스타일 + 전각(NFKC) 보강 반영.

퍼지 매칭: RapidFuzz 존재 시만 반영, 의존성 강제는 보류(옵션).

왜 이게 안전한가

현재 코드 맥락과 자연스럽게 결합: 이미 column_matcher.py에서 유사 개념의 정규화/의미 매핑을 사용 중입니다. 이번엔 헤더 행 탐지 + 퍼지 매칭 + 스테이지 통합 API까지 확장해 독립 모듈화했을 뿐이에요.

스테이지 전반 일관성: data_synchronizer_v29.py가 유연 매칭을 사용하는 흐름과도 합쳐집니다. 이제 모든 단계가 같은 리졸버를 사용.

파생 컬럼 계산과 충돌 없음: derived_columns_processor.py는 존재하는 컬럼만 집계합니다. 의미 매핑으로 실제 컬럼명을 맞춰 주면 그대로 동작합니다.

보고서 색칠 파이프라인도 커버: create_final_colored_report.py의 “Case No” 탐지 취약점(1행 가정)을 제거합니다.

리스크/엣지케이스 체크

다중 행 헤더: 2행 조합형 헤더는 현 버전에서 “최다 의미 매칭 행”을 헤더로 간주(간단 전략). 필요하면 detector.py에 “두 행 합성(flatten)” 옵션을 추가하세요.

퍼지 과매칭: 유사도가 높은 잡음 헤더가 있을 수 있으니 기본 임계치 cutoff=92로 보수적으로 설정(조정 가능).

완전 신종 헤더: 팀에서 새 별칭이 발견되면 aliases.build_alias_index(extra=...)로 동적으로 확장.

한 줄 가이드

원본 헤더가 어떻게 생겼든, 어디서 시작하든: HeaderResolver.detect_and_set_header() → resolver.resolve(required_meanings=...)만 기억하세요. 스테이지는 항상 의미 키만 바라보면 됩니다.

필요하면 바로 패치 반영본까지 써드립니다. 우선 이 설계대로 넣으면, “헤더 변칙성”은 파이프라인에서 신경 꺼도 됩니다. 깔끔하게요.

참고 사료/문맥 인용

현재 파이프라인에서의 유연 매칭·의존 파일
column_matcher.py(정규화/동의어 매칭), data_synchronizer_v29.py(유연 매칭 사용), column_definitions.py(표준 컬럼 정의), derived_columns_processor.py(존재 컬럼만 집계), create_final_colored_report.py(1행 가정 연약점)

pandas 헤더 처리/커뮤니티 논의, 헤더 자동 탐지 휴리스틱 아이디어 
Data Science Stack Exchange
+3
Pandas
+3
Pandas
+3

컬럼 정규화/퍼지 매칭 레퍼런스: pyjanitor, RapidFuzz 
rapidfuzz.github.io
+3
GitHub
+3
KDnuggets
+3

팀 규율: Python First + Tidy First + 테스트/품질 게이트(ruff/black/pytest)

