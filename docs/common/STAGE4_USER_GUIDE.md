# Stage 4: ì´ìƒì¹˜ íƒì§€ ìƒì„¸ ì‚¬ìš© ê°€ì´ë“œ

## ğŸ“‹ ê°œìš”

Stage 4ëŠ” Stage 3ì˜ ì¢…í•© ë³´ê³ ì„œ ë°ì´í„°ì—ì„œ ì´ìƒì¹˜ë¥¼ ìë™ìœ¼ë¡œ íƒì§€í•˜ê³ , ìƒ‰ìƒìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ í‘œì‹œí•˜ëŠ” ê³ ê¸‰ ë¶„ì„ ë‹¨ê³„ì…ë‹ˆë‹¤.

### ì£¼ìš” ê¸°ëŠ¥ (v3.0.1)
- **5ê°€ì§€ ì´ìƒì¹˜ ìœ í˜• íƒì§€**: ë‹¤ì–‘í•œ íŒ¨í„´ì˜ ì´ìƒì¹˜ ìë™ ì‹ë³„
- **ìƒ‰ìƒ êµ¬ë¶„ í‘œì‹œ**: ì´ìƒì¹˜ ìœ í˜•ë³„ë¡œ ë‹¤ë¥¸ ìƒ‰ìƒ ì ìš©
- **ìë™ íŒŒì¼ íƒìƒ‰**: ìµœì‹  ë³´ê³ ì„œë¥¼ ìë™ìœ¼ë¡œ ì°¾ì•„ì„œ ë¶„ì„ âœ…
- **ìƒ‰ìƒ ì ìš© ìë™í™”**: `--stage4-visualize` í”Œë˜ê·¸ë¡œ ê°„í¸ ì‹¤í–‰ âœ…
- **ìƒì„¸ ë¶„ì„ ë³´ê³ ì„œ**: ì´ìƒì¹˜ ì›ì¸ ë° ì˜í–¥ë„ ë¶„ì„
- **ë°ì´í„° í’ˆì§ˆ ê°œì„  ì œì•ˆ**: ì´ìƒì¹˜ í•´ê²° ë°©ì•ˆ ì œì‹œ

## ğŸ“ ì…ë ¥ íŒŒì¼ ìš”êµ¬ì‚¬í•­

### ì…ë ¥ íŒŒì¼ (ìë™ íƒìƒ‰)
- **íŒŒì¼ íŒ¨í„´**: `HVDC_ì…ê³ ë¡œì§_ì¢…í•©ë¦¬í¬íŠ¸_*_v3.0-corrected.xlsx`
- **ìë™ ì„ íƒ**: ê°€ì¥ ìµœì‹  íŒŒì¼ ìë™ íƒìƒ‰ âœ…
- **ì†ŒìŠ¤**: Stage 3 ì¶œë ¥ íŒŒì¼
- **í˜•ì‹**: Excel (.xlsx)
- **í•„ìˆ˜ ì‹œíŠ¸**: ì²« ë²ˆì§¸ ì‹œíŠ¸ (í†µí•©_ì›ë³¸ë°ì´í„°_Fixed)

### í•„ìˆ˜ ì»¬ëŸ¼
Stage 3 ë³´ê³ ì„œì˜ ì²« ë²ˆì§¸ ì‹œíŠ¸ì— ë‹¤ìŒ ì»¬ëŸ¼ë“¤ì´ í•„ìš”í•©ë‹ˆë‹¤:
- Case No.
- ETD/ATD, ETA/ATA
- DHL Warehouse, DSV Indoor
- íŒŒìƒ ì»¬ëŸ¼ (Total_Days, DHL_Processing_Days, DSV_Processing_Days ë“±)

## ğŸš€ ì‹¤í–‰ ë°©ë²•

### ë°©ë²• 1: ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (ê¶Œì¥) - ìƒ‰ìƒ í¬í•¨
```bash
cd hvdc_pipeline
.\run_full_pipeline.bat
# ë˜ëŠ”
python run_pipeline.py --all
```

### ë°©ë²• 2: Stage 4ë§Œ ì‹¤í–‰ - ìƒ‰ìƒ ì ìš© í¬í•¨ âœ…
```bash
cd hvdc_pipeline
python run_pipeline.py --stage 4 --stage4-visualize
```
**íŠ¹ì§•:**
- ìë™ìœ¼ë¡œ ìµœì‹  ë³´ê³ ì„œ íŒŒì¼ íƒìƒ‰
- ì´ìƒì¹˜ íƒì§€ í›„ ìƒ‰ìƒ ìë™ ì ìš©
- ì›ë³¸ íŒŒì¼ ìë™ ë°±ì—…

### ë°©ë²• 3: ìƒ‰ìƒ ì—†ì´ íƒì§€ë§Œ ì‹¤í–‰
```bash
cd hvdc_pipeline
python run_pipeline.py --stage 4
```
**íŠ¹ì§•:**
- ì´ìƒì¹˜ íƒì§€ë§Œ ìˆ˜í–‰ (JSON/Excel ë³´ê³ ì„œ ìƒì„±)
- ìƒ‰ìƒ ì ìš© ì œì™¸

### ë°©ë²• 4: ì§ì ‘ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
```bash
cd hvdc_pipeline
python scripts/stage4_anomaly/anomaly_detector.py \
  --input "data/processed/reports/HVDC_ì…ê³ ë¡œì§_ì¢…í•©ë¦¬í¬íŠ¸_*.xlsx" \
  --excel-out "data/anomaly/HVDC_anomaly_report.xlsx" \
  --visualize  # ìƒ‰ìƒ ì ìš© ì˜µì…˜
```

## ğŸ” 5ê°€ì§€ ì´ìƒì¹˜ ìœ í˜• ìƒì„¸

### 1. ì‹œê°„ ì´ìƒì¹˜ (Time Anomalies) - ë¹¨ê°„ìƒ‰
**íƒì§€ ëŒ€ìƒ**:
- ì´ ì†Œìš”ì¼ìˆ˜ê°€ ë¹„ì •ìƒì ìœ¼ë¡œ ê¸´ ê²½ìš°
- DHL ë˜ëŠ” DSV ì²˜ë¦¬ì¼ìˆ˜ê°€ ê·¹ë‹¨ì ìœ¼ë¡œ ê¸´ ê²½ìš°
- ë‚ ì§œ ìˆœì„œê°€ ë…¼ë¦¬ì ìœ¼ë¡œ ë§ì§€ ì•ŠëŠ” ê²½ìš°

**íƒì§€ ê·œì¹™**:
```python
# ì´ ì†Œìš”ì¼ìˆ˜ ì´ìƒì¹˜ (99.5% ë¶„ìœ„ìˆ˜ ì´ˆê³¼)
time_anomalies = df['Total_Days'] > df['Total_Days'].quantile(0.995)

# DHL ì²˜ë¦¬ì¼ìˆ˜ ì´ìƒì¹˜ (99% ë¶„ìœ„ìˆ˜ ì´ˆê³¼)
dhl_anomalies = df['DHL_Processing_Days'] > df['DHL_Processing_Days'].quantile(0.99)

# ë‚ ì§œ ìˆœì„œ ì´ìƒì¹˜ (ETA < ETD)
date_order_anomalies = df['ETA/ATA'] < df['ETD/ATD']
```

**ë¹„ì¦ˆë‹ˆìŠ¤ ì˜í–¥**:
- ê³ ê° ë§Œì¡±ë„ ì €í•˜
- ë¹„ìš© ì¦ê°€
- í”„ë¡œì„¸ìŠ¤ ë¹„íš¨ìœ¨ì„±

### 2. íš¨ìœ¨ì„± ì´ìƒì¹˜ (Efficiency Anomalies) - ì£¼í™©ìƒ‰
**íƒì§€ ëŒ€ìƒ**:
- ì „ì²´ íš¨ìœ¨ì„±ì´ ë¹„ì •ìƒì ìœ¼ë¡œ ë‚®ì€ ê²½ìš°
- DHL ë˜ëŠ” DSV íš¨ìœ¨ì„±ì´ ê·¹ë‹¨ì ìœ¼ë¡œ ë‚®ì€ ê²½ìš°
- íš¨ìœ¨ì„± ì§€í‘œ ê°„ ë¶ˆì¼ì¹˜ê°€ í° ê²½ìš°

**íƒì§€ ê·œì¹™**:
```python
# ì „ì²´ íš¨ìœ¨ì„± ì´ìƒì¹˜ (5% ë¶„ìœ„ìˆ˜ ë¯¸ë§Œ)
efficiency_anomalies = df['Overall_Efficiency'] < df['Overall_Efficiency'].quantile(0.05)

# DHL íš¨ìœ¨ì„± ì´ìƒì¹˜ (1% ë¶„ìœ„ìˆ˜ ë¯¸ë§Œ)
dhl_efficiency_anomalies = df['DHL_Efficiency'] < df['DHL_Efficiency'].quantile(0.01)

# íš¨ìœ¨ì„± ë¶ˆì¼ì¹˜ ì´ìƒì¹˜ (í‘œì¤€í¸ì°¨ 3ë°° ì´ˆê³¼)
efficiency_std = df['Overall_Efficiency'].std()
efficiency_mean = df['Overall_Efficiency'].mean()
efficiency_inconsistency = abs(df['Overall_Efficiency'] - efficiency_mean) > 3 * efficiency_std
```

**ë¹„ì¦ˆë‹ˆìŠ¤ ì˜í–¥**:
- ìš´ì˜ ë¹„íš¨ìœ¨ì„±
- ë¦¬ì†ŒìŠ¤ ë‚­ë¹„
- ì„œë¹„ìŠ¤ í’ˆì§ˆ ì €í•˜

### 3. ì§€ì—° ì´ìƒì¹˜ (Delay Anomalies) - ë…¸ë€ìƒ‰
**íƒì§€ ëŒ€ìƒ**:
- ì´ ì§€ì—°ì¼ìˆ˜ê°€ ë¹„ì •ìƒì ìœ¼ë¡œ ê¸´ ê²½ìš°
- DHL ë˜ëŠ” DSV ì§€ì—°ì´ ê·¹ë‹¨ì ì¸ ê²½ìš°
- ì§€ì—° íŒ¨í„´ì´ ë¹„ì •ìƒì ì¸ ê²½ìš°

**íƒì§€ ê·œì¹™**:
```python
# ì´ ì§€ì—°ì¼ìˆ˜ ì´ìƒì¹˜ (95% ë¶„ìœ„ìˆ˜ ì´ˆê³¼)
delay_anomalies = df['Total_Delay_Days'] > df['Total_Delay_Days'].quantile(0.95)

# DHL ì§€ì—° ì´ìƒì¹˜ (90% ë¶„ìœ„ìˆ˜ ì´ˆê³¼)
dhl_delay_anomalies = df['DHL_Delay_Days'] > df['DHL_Delay_Days'].quantile(0.90)

# ì§€ì—° íŒ¨í„´ ì´ìƒì¹˜ (ì—°ì† ì§€ì—°)
consecutive_delays = df['Total_Delay_Days'].rolling(window=5).sum() > 20
```

**ë¹„ì¦ˆë‹ˆìŠ¤ ì˜í–¥**:
- ê³ ê° ë¶ˆë§Œ
- ë¹„ìš© ì¦ê°€
- ì‹ ë¢°ë„ í•˜ë½

### 4. ë°ì´í„° í’ˆì§ˆ ì´ìƒì¹˜ (Data Quality Anomalies) - ë³´ë¼ìƒ‰
**íƒì§€ ëŒ€ìƒ**:
- ë°ì´í„° ì™„ì„±ë„ê°€ ê·¹ë‹¨ì ìœ¼ë¡œ ë‚®ì€ ê²½ìš°
- ì¼ê´€ì„± ì ìˆ˜ê°€ ë¹„ì •ìƒì ìœ¼ë¡œ ë‚®ì€ ê²½ìš°
- í’ˆì§ˆ ë“±ê¸‰ì´ Dë“±ê¸‰ì¸ ê²½ìš°

**íƒì§€ ê·œì¹™**:
```python
# ë°ì´í„° ì™„ì„±ë„ ì´ìƒì¹˜ (50% ë¯¸ë§Œ)
completeness_anomalies = df['Data_Completeness'] < 50

# ì¼ê´€ì„± ì ìˆ˜ ì´ìƒì¹˜ (30% ë¯¸ë§Œ)
consistency_anomalies = df['Consistency_Score'] < 30

# í’ˆì§ˆ ë“±ê¸‰ ì´ìƒì¹˜ (Dë“±ê¸‰)
quality_anomalies = df['Quality_Grade'] == 'D'
```

**ë¹„ì¦ˆë‹ˆìŠ¤ ì˜í–¥**:
- ì˜ì‚¬ê²°ì • ì˜¤ë¥˜
- ë¶„ì„ ì‹ ë¢°ë„ í•˜ë½
- í”„ë¡œì„¸ìŠ¤ ê°œì„  ì–´ë ¤ì›€

### 5. íŒ¨í„´ ì´ìƒì¹˜ (Pattern Anomalies) - íŒŒë€ìƒ‰
**íƒì§€ ëŒ€ìƒ**:
- íŠ¹ì • íŒ¨í„´ì—ì„œ ë²—ì–´ë‚˜ëŠ” ê²½ìš°
- ê³„ì ˆì„±ì´ë‚˜ íŠ¸ë Œë“œì™€ ë§ì§€ ì•ŠëŠ” ê²½ìš°
- ê·¸ë£¹ë³„ í‰ê· ì—ì„œ í¬ê²Œ ë²—ì–´ë‚˜ëŠ” ê²½ìš°

**íƒì§€ ê·œì¹™**:
```python
# ê³„ì ˆì„± ì´ìƒì¹˜ (ê³„ì ˆë³„ í‰ê· ì—ì„œ 2í‘œì¤€í¸ì°¨ ì´ˆê³¼)
seasonal_anomalies = detect_seasonal_anomalies(df, 'Total_Days')

# ê·¸ë£¹ë³„ ì´ìƒì¹˜ (ì°½ê³ ë³„ í‰ê· ì—ì„œ 3í‘œì¤€í¸ì°¨ ì´ˆê³¼)
group_anomalies = detect_group_anomalies(df, 'Warehouse', 'Total_Days')

# íŠ¸ë Œë“œ ì´ìƒì¹˜ (ì´ë™í‰ê· ì—ì„œ í¬ê²Œ ë²—ì–´ë‚¨)
trend_anomalies = detect_trend_anomalies(df, 'ETD/ATD', 'Total_Days')
```

**ë¹„ì¦ˆë‹ˆìŠ¤ ì˜í–¥**:
- ì˜ˆì¸¡ ì •í™•ë„ í•˜ë½
- ê³„íš ìˆ˜ë¦½ ì–´ë ¤ì›€
- ë¦¬ìŠ¤í¬ ê´€ë¦¬ ì‹¤íŒ¨

## ğŸ¨ ìƒ‰ìƒ í‘œì‹œ ì‹œìŠ¤í…œ

### ìƒ‰ìƒ ì½”ë“œ
```python
ANOMALY_COLORS = {
    'time_anomaly': 'FF0000',      # ë¹¨ê°„ìƒ‰ - ì‹œê°„ ì´ìƒì¹˜
    'efficiency_anomaly': 'FFA500', # ì£¼í™©ìƒ‰ - íš¨ìœ¨ì„± ì´ìƒì¹˜
    'delay_anomaly': 'FFFF00',     # ë…¸ë€ìƒ‰ - ì§€ì—° ì´ìƒì¹˜
    'quality_anomaly': '800080',   # ë³´ë¼ìƒ‰ - ë°ì´í„° í’ˆì§ˆ ì´ìƒì¹˜
    'pattern_anomaly': '0000FF'    # íŒŒë€ìƒ‰ - íŒ¨í„´ ì´ìƒì¹˜
}
```

### ìƒ‰ìƒ ì ìš© ê·œì¹™
1. **ìš°ì„ ìˆœìœ„**: ì‹œê°„ > íš¨ìœ¨ì„± > ì§€ì—° > í’ˆì§ˆ > íŒ¨í„´
2. **ì¤‘ë³µ ì²˜ë¦¬**: ì—¬ëŸ¬ ìœ í˜•ì— í•´ë‹¹í•˜ëŠ” ê²½ìš° ìš°ì„ ìˆœìœ„ ë†’ì€ ìƒ‰ìƒ ì ìš©
3. **ì…€ ë‹¨ìœ„**: ì´ìƒì¹˜ê°€ ìˆëŠ” ì…€ë§Œ ìƒ‰ìƒ ì ìš©
4. **ë¹ˆ ì…€ ì œì™¸**: ë°ì´í„°ê°€ ì—†ëŠ” ë¹ˆ ì…€ì—ëŠ” ìƒ‰ìƒ ì ìš© ì•ˆí•¨

## ğŸ“Š ì¶œë ¥ íŒŒì¼

### 1. ì´ìƒì¹˜ ë³´ê³ ì„œ (Excel)
**íŒŒì¼ ìœ„ì¹˜**: `data/anomaly/HVDC_anomaly_report.xlsx`

**ì‹œíŠ¸ êµ¬ì„±**:
- **ì‹œíŠ¸ 1**: ì´ìƒì¹˜ê°€ ìƒ‰ìƒìœ¼ë¡œ í‘œì‹œëœ ì›ë³¸ ë°ì´í„°
- **ì‹œíŠ¸ 2**: ì´ìƒì¹˜ ìœ í˜•ë³„ ìš”ì•½ í†µê³„
- **ì‹œíŠ¸ 3**: ì´ìƒì¹˜ ìƒì„¸ ë¶„ì„
- **ì‹œíŠ¸ 4**: ê°œì„  ê¶Œì¥ì‚¬í•­

### 2. ì´ìƒì¹˜ ë°ì´í„° (JSON)
**íŒŒì¼ ìœ„ì¹˜**: `data/anomaly/HVDC_anomaly_report.json`

**í¬í•¨ ë‚´ìš©**:
```json
{
  "anomaly_summary": {
    "total_anomalies": 156,
    "time_anomalies": 23,
    "efficiency_anomalies": 45,
    "delay_anomalies": 34,
    "quality_anomalies": 28,
    "pattern_anomalies": 26
  },
  "anomaly_details": [
    {
      "case_no": "208221",
      "anomaly_type": "time_anomaly",
      "severity": "high",
      "description": "ì´ ì†Œìš”ì¼ìˆ˜ 45ì¼ (ì •ìƒ ë²”ìœ„ ì´ˆê³¼)",
      "recommendation": "DHL ì²˜ë¦¬ ê³¼ì • ê²€í†  í•„ìš”"
    }
  ]
}
```

## ğŸ”„ ì²˜ë¦¬ ê³¼ì •

### 1. ì…ë ¥ ë°ì´í„° ê²€ì¦
```python
# Stage 3 ì¶œë ¥ íŒŒì¼ ì¡´ì¬ í™•ì¸
input_files = glob.glob("data/processed/reports/HVDC_ì¢…í•©ë¦¬í¬íŠ¸_*.xlsx")
if not input_files:
    raise FileNotFoundError("Stage 3 ì¶œë ¥ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

# ìµœì‹  íŒŒì¼ ì„ íƒ
latest_file = max(input_files, key=os.path.getctime)
```

### 2. ì´ìƒì¹˜ íƒì§€ ì•Œê³ ë¦¬ì¦˜ ì‹¤í–‰
```python
# ê° ì´ìƒì¹˜ ìœ í˜•ë³„ íƒì§€
anomaly_detectors = {
    'time': TimeAnomalyDetector(),
    'efficiency': EfficiencyAnomalyDetector(),
    'delay': DelayAnomalyDetector(),
    'quality': QualityAnomalyDetector(),
    'pattern': PatternAnomalyDetector()
}

anomaly_results = {}
for anomaly_type, detector in anomaly_detectors.items():
    anomaly_results[anomaly_type] = detector.detect(df)
```

### 3. ìƒ‰ìƒ ì ìš©
```python
# openpyxlì„ ì‚¬ìš©í•œ ìƒ‰ìƒ ì ìš©
from openpyxl.styles import PatternFill

for anomaly_type, anomalies in anomaly_results.items():
    color = ANOMALY_COLORS[anomaly_type]
    fill = PatternFill(start_color=color, end_color=color, fill_type="solid")

    for idx in anomalies:
        # í•´ë‹¹ í–‰ì˜ ë°ì´í„°ê°€ ìˆëŠ” ì…€ë§Œ ìƒ‰ì¹ 
        for cell in ws[idx + 2]:  # +2 for header row
            if cell.value is not None and str(cell.value).strip() != "":
                cell.fill = fill
```

### 4. ë³´ê³ ì„œ ìƒì„±
```python
# ì´ìƒì¹˜ ìš”ì•½ í†µê³„ ê³„ì‚°
summary_stats = calculate_anomaly_summary(anomaly_results)

# ìƒì„¸ ë¶„ì„ ìˆ˜í–‰
detailed_analysis = perform_detailed_analysis(df, anomaly_results)

# ê°œì„  ê¶Œì¥ì‚¬í•­ ìƒì„±
recommendations = generate_recommendations(anomaly_results, detailed_analysis)
```

## ğŸ“ˆ ì‹¤í–‰ ê²°ê³¼ í™•ì¸

### ì„±ê³µì ì¸ ì‹¤í–‰ í™•ì¸
```bash
# 1. ì¶œë ¥ íŒŒì¼ ì¡´ì¬ í™•ì¸
ls -la data/anomaly/
# HVDC_anomaly_report.xlsx, HVDC_anomaly_report.json íŒŒì¼ í™•ì¸

# 2. ì´ìƒì¹˜ ìˆ˜ í™•ì¸
python -c "
import json
with open('data/anomaly/HVDC_anomaly_report.json', 'r') as f:
    data = json.load(f)
print(f'ì´ ì´ìƒì¹˜ ìˆ˜: {data[\"anomaly_summary\"][\"total_anomalies\"]}')
for anomaly_type, count in data['anomaly_summary'].items():
    if anomaly_type != 'total_anomalies':
        print(f'{anomaly_type}: {count}ê°œ')
"
```

### ì˜ˆìƒ ì¶œë ¥ ë¡œê·¸
```
[INFO] Stage 4: ì´ìƒì¹˜ íƒì§€ ì‹œì‘
[INFO] ì…ë ¥ íŒŒì¼ ë¡œë“œ: HVDC_ì¢…í•©ë¦¬í¬íŠ¸_20250119_143022.xlsx
[INFO] ë°ì´í„° ê²€ì¦: 5,552í–‰, 38ê°œ ì»¬ëŸ¼
[INFO] ì´ìƒì¹˜ íƒì§€ ì•Œê³ ë¦¬ì¦˜ ì‹¤í–‰...
[INFO] ì‹œê°„ ì´ìƒì¹˜ íƒì§€: 23ê°œ ë°œê²¬
[INFO] íš¨ìœ¨ì„± ì´ìƒì¹˜ íƒì§€: 45ê°œ ë°œê²¬
[INFO] ì§€ì—° ì´ìƒì¹˜ íƒì§€: 34ê°œ ë°œê²¬
[INFO] ë°ì´í„° í’ˆì§ˆ ì´ìƒì¹˜ íƒì§€: 28ê°œ ë°œê²¬
[INFO] íŒ¨í„´ ì´ìƒì¹˜ íƒì§€: 26ê°œ ë°œê²¬
[INFO] ì´ ì´ìƒì¹˜: 156ê°œ (2.8%)
[INFO] ìƒ‰ìƒ ì ìš© ì¤‘...
[INFO] Excel ë³´ê³ ì„œ ìƒì„±: HVDC_anomaly_report.xlsx
[INFO] JSON ë°ì´í„° ìƒì„±: HVDC_anomaly_report.json
[SUCCESS] Stage 4 ì™„ë£Œ: 156ê°œ ì´ìƒì¹˜ íƒì§€ ë° ìƒ‰ìƒ í‘œì‹œ
```

## âš ï¸ ë¬¸ì œ í•´ê²°

### 1. ì…ë ¥ íŒŒì¼ ì—†ìŒ
**ì¦ìƒ**:
```
FileNotFoundError: [Errno 2] No such file or directory: 'HVDC_ì¢…í•©ë¦¬í¬íŠ¸_*.xlsx'
```

**ì›ì¸**: Stage 3ì´ ì‹¤í–‰ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ì¶œë ¥ íŒŒì¼ì´ ì—†ìŒ

**í•´ê²°ë°©ë²•**:
```bash
# Stage 3 ë¨¼ì € ì‹¤í–‰
python run_pipeline.py --stage 3

# ë˜ëŠ” ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
python run_pipeline.py --all
```

### 2. ì´ìƒì¹˜ íƒì§€ ì‹¤íŒ¨
**ì¦ìƒ**:
```
ValueError: ë°ì´í„°ì— í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: ['Total_Days', 'DHL_Processing_Days']
```

**ì›ì¸**: Stage 3 ì¶œë ¥ íŒŒì¼ì— íŒŒìƒ ì»¬ëŸ¼ì´ ì—†ìŒ

**í•´ê²°ë°©ë²•**:
1. **Stage 3 ì¶œë ¥ í™•ì¸**:
```bash
python -c "
import pandas as pd
df = pd.read_excel('data/processed/reports/HVDC_ì¢…í•©ë¦¬í¬íŠ¸_*.xlsx', sheet_name=0)
print('ì»¬ëŸ¼ ëª©ë¡:', df.columns.tolist())
"
```

2. **ì „ì²´ íŒŒì´í”„ë¼ì¸ ì¬ì‹¤í–‰**:
```bash
python run_pipeline.py --all
```

### 3. ìƒ‰ìƒ ì ìš© ì‹¤íŒ¨
**ì¦ìƒ**: ì´ìƒì¹˜ëŠ” íƒì§€ë˜ì—ˆì§€ë§Œ ìƒ‰ìƒì´ ì ìš©ë˜ì§€ ì•ŠìŒ

**ì›ì¸**: openpyxl ìƒ‰ìƒ ì ìš© ë¡œì§ ì˜¤ë¥˜

**í•´ê²°ë°©ë²•**:
1. **ì˜ì¡´ì„± í™•ì¸**:
```bash
pip install openpyxl
```

2. **ìƒ‰ìƒ ì ìš© ì¬ì‹œë„**:
```bash
python scripts/stage4_anomaly/apply_anomaly_colors.py \
  --input "data/processed/reports/HVDC_ì¢…í•©ë¦¬í¬íŠ¸_*.xlsx" \
  --anomaly-data "data/anomaly/HVDC_anomaly_report.json"
```

### 4. ë©”ëª¨ë¦¬ ë¶€ì¡±
**ì¦ìƒ**:
```
MemoryError: Unable to allocate array
```

**ì›ì¸**: ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì‹œ ë©”ëª¨ë¦¬ ë¶€ì¡±

**í•´ê²°ë°©ë²•**:
1. **ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬**:
```bash
python run_pipeline.py --stage 4 --chunk-size 1000
```

2. **ë©”ëª¨ë¦¬ ì •ë¦¬**:
```bash
# ë‹¤ë¥¸ í”„ë¡œê·¸ë¨ ì¢…ë£Œ
# ê°€ìƒ ë©”ëª¨ë¦¬ ì¦ê°€
```

### 5. ì´ìƒì¹˜ íƒì§€ ì •í™•ë„ ë¬¸ì œ
**ì¦ìƒ**: ë„ˆë¬´ ë§ì€ ë˜ëŠ” ë„ˆë¬´ ì ì€ ì´ìƒì¹˜ íƒì§€

**ì›ì¸**: ì´ìƒì¹˜ íƒì§€ ì„ê³„ê°’ ì„¤ì • ë¬¸ì œ

**í•´ê²°ë°©ë²•**:
1. **ì„ê³„ê°’ ì¡°ì •**:
```yaml
# config/pipeline_config.yaml
stage4:
  anomaly_thresholds:
    time_anomaly_percentile: 99.5
    efficiency_anomaly_percentile: 5.0
    delay_anomaly_percentile: 95.0
    quality_anomaly_percentile: 50.0
    pattern_anomaly_std_multiplier: 2.0
```

2. **ìˆ˜ë™ ì„ê³„ê°’ ì„¤ì •**:
```bash
python run_pipeline.py --stage 4 --custom-thresholds
```

## ğŸ”§ ê³ ê¸‰ ì„¤ì •

### ì´ìƒì¹˜ íƒì§€ ì•Œê³ ë¦¬ì¦˜ ì»¤ìŠ¤í„°ë§ˆì´ì§•
```python
# scripts/stage4_anomaly/custom_detectors.py
class CustomAnomalyDetector:
    def __init__(self, threshold_multiplier=2.0):
        self.threshold_multiplier = threshold_multiplier

    def detect(self, df):
        # ì‚¬ìš©ì ì •ì˜ ì´ìƒì¹˜ íƒì§€ ë¡œì§
        mean = df['Total_Days'].mean()
        std = df['Total_Days'].std()
        threshold = mean + self.threshold_multiplier * std
        return df['Total_Days'] > threshold
```

### ìƒ‰ìƒ ìŠ¤í‚¤ë§ˆ ì»¤ìŠ¤í„°ë§ˆì´ì§•
```python
# scripts/stage4_anomaly/color_schemes.py
CUSTOM_COLOR_SCHEMES = {
    'high_contrast': {
        'time_anomaly': 'FF0000',      # ë¹¨ê°„ìƒ‰
        'efficiency_anomaly': 'FF8C00', # ì§„í•œ ì£¼í™©ìƒ‰
        'delay_anomaly': 'FFD700',     # ê¸ˆìƒ‰
        'quality_anomaly': '8B008B',   # ì§„í•œ ë³´ë¼ìƒ‰
        'pattern_anomaly': '0000FF'    # íŒŒë€ìƒ‰
    },
    'pastel': {
        'time_anomaly': 'FFB6C1',      # ì—°í•œ ë¹¨ê°„ìƒ‰
        'efficiency_anomaly': 'FFE4B5', # ì—°í•œ ì£¼í™©ìƒ‰
        'delay_anomaly': 'FFFFE0',     # ì—°í•œ ë…¸ë€ìƒ‰
        'quality_anomaly': 'DDA0DD',   # ì—°í•œ ë³´ë¼ìƒ‰
        'pattern_anomaly': 'B0E0E6'    # ì—°í•œ íŒŒë€ìƒ‰
    }
}
```

### ë³´ê³ ì„œ í…œí”Œë¦¿ ì»¤ìŠ¤í„°ë§ˆì´ì§•
```python
# scripts/stage4_anomaly/report_templates.py
def create_custom_anomaly_report(anomaly_data, template_type="executive"):
    """ì‚¬ìš©ì ì •ì˜ ì´ìƒì¹˜ ë³´ê³ ì„œ ìƒì„±"""
    if template_type == "executive":
        # ê²½ì˜ì§„ìš© ìš”ì•½ ë³´ê³ ì„œ
        return create_executive_summary(anomaly_data)
    elif template_type == "technical":
        # ê¸°ìˆ ì§„ìš© ìƒì„¸ ë³´ê³ ì„œ
        return create_technical_report(anomaly_data)
    elif template_type == "operational":
        # ìš´ì˜ì§„ìš© ì‹¤í–‰ ë³´ê³ ì„œ
        return create_operational_report(anomaly_data)
```

## ğŸ“Š ì„±ëŠ¥ ìµœì í™”

### ì´ìƒì¹˜ íƒì§€ ì•Œê³ ë¦¬ì¦˜ ìµœì í™”
```python
# ë²¡í„°í™”ëœ ì—°ì‚° ì‚¬ìš©
def detect_anomalies_vectorized(df):
    """ë²¡í„°í™”ëœ ì´ìƒì¹˜ íƒì§€"""
    # numpy ì—°ì‚°ìœ¼ë¡œ ë¹ ë¥¸ ì²˜ë¦¬
    z_scores = np.abs((df['Total_Days'] - df['Total_Days'].mean()) / df['Total_Days'].std())
    return z_scores > 3
```

### ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”
```python
# ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬
def process_large_dataset(df, chunk_size=1000):
    """ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬"""
    for i in range(0, len(df), chunk_size):
        chunk = df.iloc[i:i+chunk_size]
        anomalies = detect_anomalies(chunk)
        yield anomalies
```

### ë³‘ë ¬ ì²˜ë¦¬
```python
# multiprocessingì„ ì‚¬ìš©í•œ ë³‘ë ¬ ì²˜ë¦¬
from multiprocessing import Pool

def parallel_anomaly_detection(df_chunks):
    """ë³‘ë ¬ ì´ìƒì¹˜ íƒì§€"""
    with Pool() as pool:
        results = pool.map(detect_anomalies, df_chunks)
    return results
```

## ğŸ“ ì¶”ê°€ ì§€ì›

### ê´€ë ¨ ë¬¸ì„œ
- [Stageë³„ ìƒì„¸ ê°€ì´ë“œ](STAGE_BY_STAGE_GUIDE.md)
- [Stage 3 ìƒì„¸ ê°€ì´ë“œ](STAGE3_USER_GUIDE.md)
- [ìƒ‰ìƒ ë¬¸ì œ í•´ê²°](COLOR_FIX_SUMMARY.md)

### ì´ìƒì¹˜ ë¶„ì„ ë„êµ¬
```bash
# ì´ìƒì¹˜ ìƒì„¸ ë¶„ì„
python scripts/stage4_anomaly/analyze_anomalies.py \
  --input "data/anomaly/HVDC_anomaly_report.json" \
  --output "anomaly_analysis.html"

# ì´ìƒì¹˜ ì‹œê°í™”
python scripts/stage4_anomaly/visualize_anomalies.py \
  --input "data/anomaly/HVDC_anomaly_report.json" \
  --output "anomaly_plots.png"
```

---

**ğŸ“… ìµœì¢… ì—…ë°ì´íŠ¸**: 2025-01-19
**ğŸ”– ë²„ì „**: v2.9.4
**ğŸ‘¥ ì‘ì„±ì**: HVDC íŒŒì´í”„ë¼ì¸ ê°œë°œíŒ€
